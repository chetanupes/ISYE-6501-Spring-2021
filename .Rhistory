plot(x[,5],x[,4], col=as.factor(y))
#Setting seed for reproducibility
set.seed(42)
#Creating SVM Model and the model summary to do find a range for C by trial and run
svm_model<-ksvm(x=as.matrix(x), y=as.factor(y),type="C-svc", kernel="vanilladot", C=2000, scaled=TRUE, cross=5)
print(svm_model)
#After doing several trial and run it was decided to test the following range of C (.0001 to 1)
#Predictions
pred<-predict(svm_model, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred == y)/nrow(credit_data)
#Now our task is to find the best value of C, within the decided range of C and then using a loop to use them
#we will also collect the training errors for each C and thus decide on the best C
err<-list() #Creating an empty error list
regu<-as.list(seq(from = 0.0001, to = 1, by = 0.0005))  #C is the regularization term
#Now running a loop to evaluate the error and using different C
for (i in 1:length(regu)){
set.seed(42)
test_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="vanilladot",
C=regu[[i]], scaled=TRUE, cross=5)
err[[i]]=test_model@error
}
#Plotting using ggplot
ggplot(data=dat,aes(x = C, y =Error)) + geom_point(alpha=0.5,color = "red")
#Importing the libraries
library(kernlab)
library(ggplot2)
library(dplyr)
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Viewing the data
head(credit_data)
#Summarizing the data
str(credit_data)
#Defining the training features (predictors variables) and target lable (response variable)
x<-credit_data[,1:10]
y<-credit_data[,11]
#Plotting using two features to find some insights
#Multiple plots were drawn with the the present plot telling that features 4 and 5 could be most important as
#can separate the data nicely. Just an observation.
plot(x[,5],x[,4], col=as.factor(y))
#Setting seed for reproducibility
set.seed(42)
#Creating SVM Model and the model summary to do find a range for C by trial and run
svm_model<-ksvm(x=as.matrix(x), y=as.factor(y),type="C-svc", kernel="vanilladot", C=2000, scaled=TRUE, cross=5)
print(svm_model)
#After doing several trial and run it was decided to test the following range of C (.0001 to 1)
#Predictions
pred<-predict(svm_model, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred == y)/nrow(credit_data)
#Now our task is to find the best value of C, within the decided range of C and then using a loop to use them
#we will also collect the training errors for each C and thus decide on the best C
err<-list() #Creating an empty error list
regu<-as.list(seq(from = 0.0001, to = 1, by = 0.0005))  #C is the regularization term
#Now running a loop to evaluate the error and using different C
for (i in 1:length(regu)){
set.seed(42)
test_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="vanilladot",
C=regu[[i]], scaled=TRUE, cross=5)
err[[i]]=test_model@error
}
#Plotting using ggplot
dat<-data.frame(C=unlist(regu), Error=unlist(err)) #Putting C and erron in a Data Frame
ggplot(data=dat,aes(x = C, y =Error)) + geom_point(alpha=0.5,color = "red")
#Sorting the dataframe based on least error and then using the corresponding C for the best model
dat_sort<-dat[order(dat$Error),]
best_c<-dat_sort[1,1]
#Model based on best C
best_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="vanilladot",
C=best_c, scaled=TRUE, cross=5)
#Predictions
pred_new<-predict(best_model, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred_new == y)/nrow(credit_data)
#Finding the coefficient and intercept
coff<-colSums(best_model@xmatrix[[1]]*best_model@coef[[1]])
intercept<-best_model@b
```{r message=FALSE}
coff
intercept
#Importing the libraries
library(kernlab)
library(ggplot2)
library(dplyr)
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Viewing the data
head(credit_data)
#Summarizing the data
str(credit_data)
#Defining the training features (predictors variables) and target lable (response variable)
x<-credit_data[,1:10]
y<-credit_data[,11]
#Plotting using two features to find some insights
#Multiple plots were drawn with the the present plot telling that features 4 and 5 could be most important as
#can separate the data nicely. Just an observation.
plot(x[,5],x[,4], col=as.factor(y))
#Setting seed for reproducibility
set.seed(42)
#Creating SVM Model and the model summary to do find a range for C by trial and run
svm_model<-ksvm(x=as.matrix(x), y=as.factor(y),type="C-svc", kernel="vanilladot", C=0.01, scaled=TRUE, cross=5)
#After doing several trial and run it was decided to test the following range of C (.0001 to 1)
#Predictions
pred<-predict(svm_model, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred == y)/nrow(credit_data)
#Now our task is to find the best value of C, within the decided range of C and then using a loop to use them
#we will also collect the training errors for each C and thus decide on the best C
err<-list() #Creating an empty error list
regu<-as.list(seq(from = 0.0001, to = 1, by = 0.0005))  #C is the regularization term
#Now running a loop to evaluate the error and using different C
for (i in 1:length(regu)){
set.seed(42)
test_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="vanilladot",
C=regu[[i]], scaled=TRUE, cross=5)
err[[i]]=test_model@error
}
#Plotting using ggplot
dat<-data.frame(C=unlist(regu), Error=unlist(err)) #Putting C and error in a Data Frame
ggplot(data=dat,aes(x = C, y =Error)) + geom_point(alpha=0.5,color = "red")
#Sorting the dataframe based on least error and then using the corresponding C for the best model
dat_sort<-dat[order(dat$Error),]
best_c<-dat_sort[1,1]
#Model based on best C
best_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="vanilladot",
C=best_c, scaled=TRUE, cross=5)
#Predictions
pred_new<-predict(best_model, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred_new == y)/nrow(credit_data)
#Finding the coefficient and intercept
coff<-colSums(best_model@xmatrix[[1]]*best_model@coef[[1]])
intercept<-best_model@b
$$ y=A1*-0.002061415 + A2*0.011215933 + A*30.023437737+A8*0.104176966 +
A9*0.507725910 + A10*-0.230008684 + A11* 0.169276410 + A12*-0.003537710 +
A14*-0.019113050 + A15*0.102202961 + 0.0878633 $$
###############################################################################
Using radial Kernal
#Finding the coefficient and intercept
coff<-colSums(best_model@xmatrix[[1]]*best_model@coef[[1]])
intercept<-best_model@b
###############################################################################
Using radial Kernal
###############################################################################
#Using Radial Kernal
###############################################################################
err_non<-list()
#importing the libraries
library(kernlab)
library(ggplot2)
library(dplyr)
#Getting the working directory
getwd()
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Viewing the data
View(credit_data)
#Summarizing the data
str(credit_data)
x<-credit_data[,1:10]
y<-credit_data[,11]
plot(x[,5],x[,4], col=as.factor(y))
###############################################################################
#Using Radial Kernal
###############################################################################
err_non<-list()
regu_non<-as.list(seq(from = 0.5, to = 200, by = 0.5))
#Now running a loop to evaluate the error and using different C
for (i in 1:length(regu_non)){
set.seed(42)
test_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="rbfdot",
C=regu_non[[i]], scaled=TRUE, cross=5)
err_non[[i]]=test_model@error
}
#Plotting using ggplot needs to put C and errot in a dataframe
dat_non<-data.frame(C=unlist(regu_non), Error=unlist(err_non))
#Plotting using ggplot
ggplot(data=dat_non,aes(x = C, y =Error)) + geom_point(alpha=0.5,color = "red")
dat_sort_non<-dat_non[order(dat_non$Error),]
best_non_c<-dat_sort_non[1,1]
#Model based on best C
best_model_non<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="rbfdot",
C=best_non_c, scaled=TRUE, cross=5)
#Predictions
pred_non_new<-predict(best_model_non, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred_non_new == y)/nrow(credit_data)
coff_non<-colSums(best_model@xmatrix[[1]]*best_model@coef[[1]])
dat_sort_non<-dat_non[order(dat_non$Error),]
best_non_c<-dat_sort_non[1,1]
#Model based on best C
best_model_non<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="rbfdot",
C=best_non_c, scaled=TRUE, cross=5)
#Predictions
pred_non_new<-predict(best_model_non, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred_non_new == y)/nrow(credit_data)
coff_non<-colSums(best_model@xmatrix[[1]]*best_model@coef[[1]])
intercept_non<-best_model@b
coff_non<-colSums(best_model_non@xmatrix[[1]]*best_model_non@coef[[1]])
intercept_non<-best_mode_nonl@b
intercept_non<-best_mode_non@b
#Model based on best C
best_model_non<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="rbfdot",
C=best_non_c, scaled=TRUE, cross=5)
#Predictions
pred_non_new<-predict(best_model_non, x[,1:10])
#Percentage of model predictions matching actual classifications
sum(pred_non_new == y)/nrow(credit_data)
coff_non<-colSums(best_model_non@xmatrix[[1]]*best_model_non@coef[[1]])
intercept_non<-best_mode_non@b
intercept_non<-best_model_non@b
coff_non
intercept_non
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=unlist(k), Accuracy=unlist(accu))
k<-as.list(seq(from = 1, to = 50, by =1))  #C is the regularization term
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=unlist(k), Accuracy=unlist(accu))
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=k, Accuracy=unlist(accu))
for (j in 1:length(k)){
for (i in 1:nrow(credit_data)){
model_knn = kknn(R1~.,
credit_data[-i,],
credit_data[i,],
k = j,
scale = TRUE)
pred_knn = fitted(model_knn)
pre[[i]]<-ifelse(pred_knn>0.5,1,0)
}
accu[[j]]=sum(pre == credit_data[,11]) / nrow(credit_data)
}
library(kknn)
#Getting the working directory
getwd()
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Summerizing the data
str(credit_data)
k<-as.list(seq(from = 1, to = 50, by =1))  #C is the regularization term
pre= list()
accu<-list()
for (j in 1:length(k)){
for (i in 1:nrow(credit_data)){
model_knn = kknn(R1~.,
credit_data[-i,],
credit_data[i,],
k = j,
scale = TRUE)
pred_knn = fitted(model_knn)
pre[[i]]<-ifelse(pred_knn>0.5,1,0)
}
accu[[j]]=sum(pre == credit_data[,11]) / nrow(credit_data)
}
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=k, Accuracy=unlist(accu))
ggplot(data=dat_non,aes(x = C, y =Error)) + geom_point(alpha=0.5,color = "red")
library(kknn)
#Getting the working directory
getwd()
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Summerizing the data
str(credit_data)
k<-as.list(seq(from = 1, to = 50, by =1))  #C is the regularization term
pre= list()
accu<-list()
for (j in 1:length(k)){
for (i in 1:nrow(credit_data)){
model_knn = kknn(R1~.,
credit_data[-i,],
credit_data[i,],
k = j,
scale = TRUE)
pred_knn = fitted(model_knn)
pre[[i]]<-ifelse(pred_knn>0.5,1,0)
}
accu[[j]]=sum(pre == credit_data[,11]) / nrow(credit_data)
}
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=k, Accuracy=unlist(accu))
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=k, Accuracy=unlist(accu))
ggplot(data=dat,aes(x = k, y =Accuracy)) + geom_point(alpha=0.5,color = "red")
View(dat)
View(dat)
View(k)
View(k)
View(accu)
View(accu)
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=unlist(k), Accuracy=unlist(accu))
View(dat)
View(dat)
View(pre)
View(pre)
ggplot(data=dat,aes(x = k, y =Accuracy)) + geom_point(alpha=0.5,color = "red")
best_k<-dat[1,1]
View(dat)
View(dat)
#Sorting the dataframe based on least error
dat<-dat_non[order(dat_non$Error),]
#Sorting the dataframe based on least error
dat<-dat[order(dat$Accuracy),]
best_k<-dat[1,1]
View(dat)
View(dat)
#Sorting the dataframe based on least error
dat_sort_non<-dat_non[order(dat_non$Error),]
library(kknn)
library(kknn)
#Getting the working directory
getwd()
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Summerizing the data
str(credit_data)
k<-as.list(seq(from = 1, to = 50, by =1))  #C is the regularization term
pre= list()
accu<-list()
for (j in 1:length(k)){
for (i in 1:nrow(credit_data)){
model_knn = kknn(R1~.,
credit_data[-i,],
credit_data[i,],
k = j,
scale = TRUE)
pred_knn = fitted(model_knn)
pre[[i]]<-ifelse(pred_knn>0.5,1,0)
}
accu[[j]]=sum(pre == credit_data[,11]) / nrow(credit_data)
}
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=unlist(k), Accuracy=unlist(accu))
ggplot(data=dat,aes(x = k, y =Accuracy)) + geom_point(alpha=0.5,color = "red")
#Sorting the dataframe based on least error
dat<-dat[order(dat$Accuracy),]
best_k<-dat[1,1]
View(dat)
View(dat)
#importing the libraries
library(kernlab)
library(ggplot2)
library(dplyr)
#Getting the working directory
getwd()
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
###############################################################################
#Using Radial Kernal
###############################################################################
err_non<-list()
regu_non<-as.list(seq(from = 0.5, to = 200, by = 0.5))
#Now running a loop to evaluate the error and using different C
for (i in 1:length(regu_non)){
set.seed(42)
test_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="rbfdot",
C=regu_non[[i]], scaled=TRUE, cross=5)
err_non[[i]]=test_model@error
}
x<-credit_data[,1:10]
y<-credit_data[,11]
regu_non<-as.list(seq(from = 0.5, to = 200, by = 0.5))
#Now running a loop to evaluate the error and using different C
for (i in 1:length(regu_non)){
set.seed(42)
test_model<-ksvm(x=as.matrix(x), y=as.factor(y), type="C-svc",kernel="rbfdot",
C=regu_non[[i]], scaled=TRUE, cross=5)
err_non[[i]]=test_model@error
}
#To plot using ggplot C and error are put in a dataframe
dat_non<-data.frame(C=unlist(regu_non), Error=unlist(err_non))
ggplot(data=dat_non,aes(x = C, y =Error)) + geom_point(alpha=0.5,color = "red")
#Sorting the dataframe based on least error
dat_sort_non<-dat_non[order(dat_non$Error),]
View(dat_sort_non)
View(dat_sort_non)
best_non_c<-dat_sort_non[1,1]
View(dat)
View(dat)
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=unlist(k), Accuracy=unlist(accu))
ggplot(data=dat,aes(x = k, y =Accuracy)) + geom_point(alpha=0.5,color = "red")
#Sorting the dataframe based on least error
dat<-dat[order(dat$Accuracy),]
View(dat)
View(dat)
View(dat_non)
View(dat_non)
#Sorting the dataframe based on least error
dat_sort_non<-dat_non[order(dat_non$Error),]
View(dat_non)
View(dat_non)
best_non_c<-dat_sort_non[1,1]
View(dat_sort_non)
View(dat_sort_non)
#Sorting the dataframe based on least error
dat_sort<-dat[order(dat$Accuracy),]
View(dat_sort)
View(dat_sort)
#Sorting the dataframe based on least error
dat_sort<-desc(dat$Accuracy)
#Sorting the dataframe based on least error
dat_sort<-dat[desc(dat$Accuracy)]
View(dat_sort)
View(dat_sort)
#Sorting the dataframe based on least error
dat_sort<-dat[desc(dat$Accuracy),]
View(dat_sort)
View(dat_sort)
#Sorting the dataframe based on least error
dat_sort<-dat[order(-Accuracy),]
View(dat_sort)
View(dat_sort)
library(kknn)
#Getting the working directory
getwd()
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Summerizing the data
str(credit_data)
k<-as.list(seq(from = 1, to = 50, by =1))  #C is the regularization term
pre= list()
accu<-list()
for (j in 1:length(k)){
for (i in 1:nrow(credit_data)){
model_knn = kknn(R1~.,
credit_data[-i,],
credit_data[i,],
k = j,
scale = TRUE)
pred_knn = fitted(model_knn)
pre[[i]]<-ifelse(pred_knn>0.5,1,0)
}
accu[[j]]=sum(pre == credit_data[,11]) / nrow(credit_data)
}
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=unlist(k), Accuracy=unlist(accu))
ggplot(data=dat,aes(x = k, y =Accuracy)) + geom_point(alpha=0.5,color = "red")
View(dat)
View(dat)
#Sorting the dataframe based on least error
dat_sort<-dat[order(-dat$Accuracy),]
View(dat_sort)
View(dat_sort)
best_k<-dat[1,1]
best_k<-dat_sort[1,1]
print(best_k)
#Viewing the data
head(credit_data)
message('Accuracy of the model using the best k: ', dat_sort[1,2])
message('Best k: ',best_k)
?train.kknn
kknn
library(kknn)
kknn
train.kknn
View(accu)
View(accu)
model_knn
model_knn1 = kknn(R1~.,
credit_data[-i,],
credit_data[i,],
k = 5,
scale = TRUE)
model_knn1
View(model_knn1)
View(model_knn1)
model_knn1 = kknn(R1~.,
credit_data[-1,],
credit_data[1,],
k = 5,
scale = TRUE)
model_knn1
View(model_knn1)
#Installing kkNN package
install.packages("kknn")
install.packages("kknn")
library(kknn)
#Getting the working directory
getwd()
#Reading the text file
credit_data<-read.table('credit_card_data-headers.txt', sep="", header = TRUE)
#Viewing the data
head(credit_data)
#Summarizing the data
str(credit_data)
k<-as.list(seq(from = 1, to = 50, by =1))
pre<-list()
accu<-list()
for (j in 1:length(k)){
for (i in 1:nrow(credit_data)){
model_knn = kknn(R1~.,
credit_data[-i,],
credit_data[i,],
k = j,
scale = TRUE)
pred_knn = fitted(model_knn)
pre[[i]]<-ifelse(pred_knn>0.5,1,0)
}
accu[[j]]=sum(pre == credit_data[,11]) / nrow(credit_data)
}
#To plot using ggplot k and accuracy are put in a dataframe
dat<-data.frame(k=unlist(k), Accuracy=unlist(accu))
ggplot(data=dat,aes(x = k, y =Accuracy)) + geom_point(alpha=0.5,color = "red")
#Sorting the dataframe based on least error
dat_sort<-dat[order(-dat$Accuracy),]
best_k<-dat_sort[1,1]
message('Best k: ',best_k)
message('Accuracy of the model using the best k: ', dat_sort[1,2])
