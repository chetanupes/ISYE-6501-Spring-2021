Purpose_A41 + Purpose_A42 + Purpose_A43 +
Savings.account.bonds_A62 + Savings.account.bonds_A65 +
Other.debtors...guarantors_A102 +
Other.installment.plans_A143 +
foreign.worker_A202 + `Duration in month` + `Credit amount` +
`Installment rate in % disposable income`,
family = binomial, data = train_data)
summary(model1)
#We will keep model1 as final model as most of the variable being significant
#Now changing the test data with the same variables as in the model1 for
#predictions
test_new<-test_data[,c('Checking.account.Status_A13',
'Checking.account.Status_A14','Credit.history_A34',
'Purpose_A41','Purpose_A42','Purpose_A43',
'Savings.account.bonds_A62','Savings.account.bonds_A65',
'Other.debtors...guarantors_A102',
'Other.installment.plans_A143',
'foreign.worker_A202','Duration in month','Credit amount',
'Installment rate in % disposable income','Customer_Status')]
#Calculate the predicted probabilities for the test data using 0.5 as threshold
predicted<- predict(model1,test_new,type = "response" )
predicted_int<-as.integer(predicted>0.5)
tab<-table(predicted_int, test_new$Customer_Status)
con<-confusionMatrix(tab)
con
#Accuracy predicted with 0.5 threshold is 75%
#Trying some more thresholds to see the accuracy
#Threshold 0.3
predicted_int1<-as.integer(predicted>0.3)
tab1<-table(predicted_int1, test_new$Customer_Status)
con1<-confusionMatrix(tab1)
con1
#Accuracy predicted with 0.3 threshold is 72%
#Threshold 0.6
predicted_int2<-as.integer(predicted>0.6)
tab2<-table(predicted_int2, test_new$Customer_Status)
con2<-confusionMatrix(tab2)
con2
#Accuracy predicted with 0.6 threshold is 71%.
#Accuracy basically tells us how effective the model was in characterizing bad
#and good status.
#Thus the accuracy is best between 0.5-0.6 threshold
#Plotting ROC
roc_curve<-roc(test_new$Customer_Status,predicted)
plot(roc_curve)
roc_curve$auc
install.packages(c("cachem", "data.table", "desc", "dplyr", "farver", "ipred", "isoband", "lubridate", "MatrixModels", "pbkrtest", "pillar", "pkgload", "ps", "quantreg", "RcppArmadillo", "rio", "SparseM", "tibble", "tidyr", "tinytex", "waldo", "xfun", "zoo"))
install.packages(c("cachem", "data.table", "desc", "dplyr", "farver", "ipred", "isoband", "lubridate", "MatrixModels", "pbkrtest", "pillar", "pkgload", "ps", "quantreg", "RcppArmadillo", "rio", "SparseM", "tibble", "tidyr", "tinytex", "waldo", "xfun", "zoo"))
install.packages(c("cachem", "data.table", "desc", "dplyr", "farver", "ipred", "isoband", "lubridate", "MatrixModels", "pbkrtest", "pillar", "pkgload", "ps", "quantreg", "RcppArmadillo", "rio", "SparseM", "tibble", "tidyr", "tinytex", "waldo", "xfun", "zoo"))
install.packages(c("cachem", "data.table", "desc", "dplyr", "farver", "ipred", "isoband", "lubridate", "MatrixModels", "pbkrtest", "pillar", "pkgload", "ps", "quantreg", "RcppArmadillo", "rio", "SparseM", "tibble", "tidyr", "tinytex", "waldo", "xfun", "zoo"))
install.packages(c("cachem", "data.table", "desc", "dplyr", "farver", "ipred", "isoband", "lubridate", "MatrixModels", "pbkrtest", "pillar", "pkgload", "ps", "quantreg", "RcppArmadillo", "rio", "SparseM", "tibble", "tidyr", "tinytex", "waldo", "xfun", "zoo"))
install.packages("pandocfilters")
tinytex::tlmgr_install("pdfcrop")
Sys.setenv(R_GSCMD="C:/Program Files/gs/gs9.53.3/bin/gswin64.exe")
tools::find_gs_cmd()
Sys.getenv("R_GSCMD")
Sys.setenv(R_GSCMD="C:/Program Files/gs/gs9.53.3/bin/gswin64.exe")
tools::find_gs_cmd()
Sys.getenv("R_GSCMD")
library(randomForest)
install.packages(c("data.table", "RcppArmadillo", "xfun", "zoo"))
#Random forest
#RF model
rf<-randomForest(Crime~., data=crime_data)
summary(rf)
print(rf)
#predicting using RF model
pred_rf<-predict(rf)
#Calculating R2 for RF model
SSE_rf<-sum((pred_rf-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf<-1-SSE_rf/SST
#Running CV on RF Model and check the R2
rf_cv<-rfcv(trainx = crime_data[,1:15], trainy = crime_data$Crime,
cv.fold = 10)
print(rf_cv)
plot(rf_cv$error)
#predicting using RF_CV model
pred_rf_cv<-rf_cv$predicted[1]
#Calculating R2 for RF CV model
SSE_rf_cv1<-sum((pred_rf_cv-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf_cv<-1-SSE_rf_cv1/SST
#RF model
rf<-randomForest(Crime~., data=crime_data)
summary(rf)
print(rf)
#predicting using RF model
pred_rf<-predict(rf)
#Calculating R2 for RF model
SSE_rf<-sum((pred_rf-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf<-1-SSE_rf/SST
#Running CV on RF Model and check the R2
rf_cv<-rfcv(trainx = crime_data[,1:15], trainy = crime_data$Crime,
cv.fold = 10)
print(rf_cv)
plot(rf_cv$error)
#predicting using RF model
pred_rf_cv<-rf_cv$predicted[1]
#Calculating R2 for RF CV model
SSE_rf_cv1<-sum((pred_rf_cv-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf_cv<-1-SSE_rf_cv1/SST
#Random forest
#RF model
rf<-randomForest(Crime~., data=crime_data)
summary(rf)
print(rf)
#predicting using RF model
pred_rf<-predict(rf)
#Calculating R2 for RF model
SSE_rf<-sum((pred_rf-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf<-1-SSE_rf/SST
#Running CV on RF Model and check the R2
rf_cv<-rfcv(trainx = crime_data[,1:15], trainy = crime_data$Crime,
cv.fold = 10)
print(rf_cv)
plot(rf_cv$error)
#predicting using RF_CV model
pred_rf_cv<-rf_cv$predicted[1]
#Calculating R2 for RF CV model
SSE_rf_cv1<-sum((pred_rf_cv-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf_cv<-1-SSE_rf_cv1/SST
library(reshape2)
library(dummy)
library(caret)
library(MASS)
library(car)
library(e1071)
library(pROC)
#Getting the training and test data
credit_data<-read.table('germancredit.txt', sep = "", header = TRUE)
summary(credit_data)
#Renaming the columns as per the description in the document
newnames<-c('Checking account Status','Duration in month',
'Credit history','Purpose','Credit amount',
'Savings account/bonds','Employment since',
'Installment rate in % disposable income','Status& Sex',
'Other debtors / guarantors','Residence since','Property',
'Age in years','Other installment plans','Housing',
'Number of existing credits at this bank',
'Job','People being liable to provide maintenance for',
'Telephone','foreign worker', 'Customer_Status')
colnames(credit_data)<-newnames
#Exploratory Data Analysis
#The document shows that we have 7 numeric and 13 categorical predictors
#Let's group the numerical variables to visualize the data
num<-scale(credit_data[,c(2,5,8,11,13,16,18)])
num<-melt(num)
#Box plot to view the outliers
ggplot(num,aes(x=Var2, y=value))+geom_boxplot()+
scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 10))
#Credit amount show quite a large number of outliers but we not
#remove them for this analysis.
#The next step is to create dummy variables for the categorical variables
#using the dummy package
categorical<-credit_data[,-c(2,5,8,11,13,16,18,21)]
numerical<-credit_data[,c(2,5,8,11,13,16,18,21)]
cat_dummy<-dummy(categorical)
#Now we need to drop one variable from each category to avoid multi-collinearity
#in our model. Thus we will drop one dummy variable from each category
cat_dummy_new<-cat_dummy[,-c(1,5,10,20,25,30,34,37,41,44,47,51,53)]
#Now let's combine the numerical and dummy data together
new_data<-cbind(cat_dummy_new,numerical)
new_data$`Customer_Status`<-ifelse(new_data$`Customer_Status`==1,1,0)
#Converting response to 1 an 0, 0=Good and 1=Bad
#Splitting the data into test train.
#Also, we must be careful that response data is proportionately split into train
#and test data. Below table shows we have 699 Good and 300 Bad values
table(new_data$`Customer_Status`)
#Setting seed
set.seed(42)
#Using create Data partition
train_index<-createDataPartition(y=new_data$`Customer_Status`, p=0.7,
times = 1, list = FALSE)
#Training data
train_data<-new_data[train_index,]
#Testing data
test_data<-new_data[-train_index,]
# Initial Model with all variables
initial_model <- glm(train_data$`Customer_Status`~.,family = binomial,
data=train_data)
summary(initial_model)
#Now looking at the p-values of the variable, lot's of them are not significant
#and thus we can build a new model with only the significant variables. We will
#use the p value threshold as 0.05
#Model with most significant variables from the initial model
model1<-glm(formula = train_data$Customer_Status ~ Checking.account.Status_A13 +
Checking.account.Status_A14 + Credit.history_A34 +
Purpose_A41 + Purpose_A42 + Purpose_A43 +
Savings.account.bonds_A62 + Savings.account.bonds_A65 +
Other.debtors...guarantors_A102 +
Other.installment.plans_A143 +
foreign.worker_A202 + `Duration in month` + `Credit amount` +
`Installment rate in % disposable income`,
family = binomial, data = train_data)
summary(model1)
#We will keep model1 as final model as most of the variable being significant
#Now changing the test data with the same variables as in the model1 for
#predictions
test_new<-test_data[,c('Checking.account.Status_A13',
'Checking.account.Status_A14','Credit.history_A34',
'Purpose_A41','Purpose_A42','Purpose_A43',
'Savings.account.bonds_A62','Savings.account.bonds_A65',
'Other.debtors...guarantors_A102',
'Other.installment.plans_A143',
'foreign.worker_A202','Duration in month','Credit amount',
'Installment rate in % disposable income','Customer_Status')]
#Calculate the predicted probabilities for the test data using 0.5 as threshold
predicted<- predict(model1,test_new,type = "response" )
predicted_int<-as.integer(predicted>0.5)
tab<-table(predicted_int, test_new$Customer_Status)
con<-confusionMatrix(tab)
con
#Accuracy predicted with 0.5 threshold is 75%
#Trying some more thresholds to see the accuracy
#Threshold 0.3
predicted_int1<-as.integer(predicted>0.3)
tab1<-table(predicted_int1, test_new$Customer_Status)
con1<-confusionMatrix(tab1)
con1
#Accuracy predicted with 0.3 threshold is 72%
#Threshold 0.6
predicted_int2<-as.integer(predicted>0.6)
tab2<-table(predicted_int2, test_new$Customer_Status)
con2<-confusionMatrix(tab2)
con2
#Accuracy predicted with 0.6 threshold is 71%.
#Accuracy basically tells us how effective the model was in characterizing bad
#and good status.
#Thus the accuracy is best between 0.5-0.6 threshold
#Plotting ROC
roc_curve<-roc(test_new$Customer_Status,predicted)
plot(roc_curve)
roc_curve$auc
#Random forest
#RF model
rf<-randomForest(Crime~., data=crime_data)
summary(rf)
print(rf)
#predicting using RF model
pred_rf<-predict(rf)
#Calculating R2 for RF model
SSE_rf<-sum((pred_rf-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf<-1-SSE_rf/SST
#Running CV on RF Model and check the R2
rf_cv<-rfcv(trainx = crime_data[,1:15], trainy = crime_data$Crime,
cv.fold = 10)
print(rf_cv)
plot(rf_cv$error)
#predicting using RF_CV model
pred_rf_cv<-rf_cv$predicted[1]
#Calculating R2 for RF CV model
SSE_rf_cv1<-sum((pred_rf_cv-crime_data[16])^2)
SST<-sum((crime_data$Crime-mean(crime_data$Crime))^2)
R2_rf_cv<-1-SSE_rf_cv1/SST
library(reshape2)
library(dummy)
library(caret)
library(MASS)
library(car)
library(e1071)
library(pROC)
#Getting the training and test data
credit_data<-read.table('germancredit.txt', sep = "", header = TRUE)
summary(credit_data)
#Renaming the columns as per the description in the document
newnames<-c('Checking account Status','Duration in month',
'Credit history','Purpose','Credit amount',
'Savings account/bonds','Employment since',
'Installment rate in % disposable income','Status& Sex',
'Other debtors / guarantors','Residence since','Property',
'Age in years','Other installment plans','Housing',
'Number of existing credits at this bank',
'Job','People being liable to provide maintenance for',
'Telephone','foreign worker', 'Customer_Status')
colnames(credit_data)<-newnames
#Exploratory Data Analysis
#The document shows that we have 7 numeric and 13 categorical predictors
#Let's group the numerical variables to visualize the data
num<-scale(credit_data[,c(2,5,8,11,13,16,18)])
num<-melt(num)
#Box plot to view the outliers
ggplot(num,aes(x=Var2, y=value))+geom_boxplot()+
scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 10))
#Credit amount show quite a large number of outliers but we not
#remove them for this analysis.
#The next step is to create dummy variables for the categorical variables
#using the dummy package
categorical<-credit_data[,-c(2,5,8,11,13,16,18,21)]
numerical<-credit_data[,c(2,5,8,11,13,16,18,21)]
cat_dummy<-dummy(categorical)
#Now we need to drop one variable from each category to avoid multi-collinearity
#in our model. Thus we will drop one dummy variable from each category
cat_dummy_new<-cat_dummy[,-c(1,5,10,20,25,30,34,37,41,44,47,51,53)]
#Now let's combine the numerical and dummy data together
new_data<-cbind(cat_dummy_new,numerical)
new_data$`Customer_Status`<-ifelse(new_data$`Customer_Status`==1,1,0)
#Converting response to 1 an 0, 0=Good and 1=Bad
#Splitting the data into test train.
#Also, we must be careful that response data is proportionately split into train
#and test data. Below table shows we have 699 Good and 300 Bad values
table(new_data$`Customer_Status`)
#Setting seed
set.seed(42)
#Using create Data partition
train_index<-createDataPartition(y=new_data$`Customer_Status`, p=0.7,
times = 1, list = FALSE)
#Training data
train_data<-new_data[train_index,]
#Testing data
test_data<-new_data[-train_index,]
# Initial Model with all variables
initial_model <- glm(train_data$`Customer_Status`~.,family = binomial,
data=train_data)
summary(initial_model)
#Now looking at the p-values of the variable, lot's of them are not significant
#and thus we can build a new model with only the significant variables. We will
#use the p value threshold as 0.05
#Model with most significant variables from the initial model
model1<-glm(formula = train_data$Customer_Status ~ Checking.account.Status_A13 +
Checking.account.Status_A14 + Credit.history_A34 +
Purpose_A41 + Purpose_A42 + Purpose_A43 +
Savings.account.bonds_A62 + Savings.account.bonds_A65 +
Other.debtors...guarantors_A102 +
Other.installment.plans_A143 +
foreign.worker_A202 + `Duration in month` + `Credit amount` +
`Installment rate in % disposable income`,
family = binomial, data = train_data)
summary(model1)
#We will keep model1 as final model as most of the variable being significant
#Now changing the test data with the same variables as in the model1 for
#predictions
test_new<-test_data[,c('Checking.account.Status_A13',
'Checking.account.Status_A14','Credit.history_A34',
'Purpose_A41','Purpose_A42','Purpose_A43',
'Savings.account.bonds_A62','Savings.account.bonds_A65',
'Other.debtors...guarantors_A102',
'Other.installment.plans_A143',
'foreign.worker_A202','Duration in month','Credit amount',
'Installment rate in % disposable income','Customer_Status')]
#Calculate the predicted probabilities for the test data using 0.5 as threshold
predicted<- predict(model1,test_new,type = "response" )
predicted_int<-as.integer(predicted>0.5)
tab<-table(predicted_int, test_new$Customer_Status)
con<-confusionMatrix(tab)
con
#Accuracy predicted with 0.5 threshold is 75%
#Trying some more thresholds to see the accuracy
#Threshold 0.3
predicted_int1<-as.integer(predicted>0.3)
tab1<-table(predicted_int1, test_new$Customer_Status)
con1<-confusionMatrix(tab1)
con1
#Accuracy predicted with 0.3 threshold is 72%
#Threshold 0.6
predicted_int2<-as.integer(predicted>0.6)
tab2<-table(predicted_int2, test_new$Customer_Status)
con2<-confusionMatrix(tab2)
con2
#Accuracy predicted with 0.6 threshold is 71%.
#Accuracy basically tells us how effective the model was in characterizing bad
#and good status.
#Thus the accuracy is best between 0.5-0.6 threshold
#Plotting ROC
roc_curve<-roc(test_new$Customer_Status,predicted)
plot(roc_curve)
roc_curve$auc
library(reshape2)
library(dummy)
library(caret)
library(MASS)
library(car)
library(e1071)
library(pROC)
#Getting the training and test data
credit_data<-read.table('germancredit.txt', sep = "", header = TRUE)
summary(credit_data)
#Renaming the columns as per the description in the document
newnames<-c('Checking account Status','Duration in month',
'Credit history','Purpose','Credit amount',
'Savings account/bonds','Employment since',
'Installment rate in % disposable income','Status& Sex',
'Other debtors / guarantors','Residence since','Property',
'Age in years','Other installment plans','Housing',
'Number of existing credits at this bank',
'Job','People being liable to provide maintenance for',
'Telephone','foreign worker', 'Customer_Status')
colnames(credit_data)<-newnames
num<-scale(credit_data[,c(2,5,8,11,13,16,18)])
num<-melt(num)
#Box plot to view the outliers
ggplot(num,aes(x=Var2, y=value))+geom_boxplot()+
scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 10))
#The next step is to create dummy variables for the categorical variables
#using the dummy package
categorical<-credit_data[,-c(2,5,8,11,13,16,18,21)]
numerical<-credit_data[,c(2,5,8,11,13,16,18,21)]
cat_dummy<-dummy(categorical)
cat_dummy_new<-cat_dummy[,-c(1,5,10,20,25,30,34,37,41,44,47,51,53)]
#Now let's combine the numerical and dummy data together
new_data<-cbind(cat_dummy_new,numerical)
new_data$`Customer_Status`<-ifelse(new_data$`Customer_Status`==1,1,0)
table(new_data$`Customer_Status`)
#Setting seed
set.seed(42)
#Using create Data partition
train_index<-createDataPartition(y=new_data$`Customer_Status`, p=0.7,
times = 1, list = FALSE)
#Training data
train_data<-new_data[train_index,]
#Testing data
test_data<-new_data[-train_index,]
# Initial Model with all variables
initial_model <- glm(train_data$`Customer_Status`~.,family = binomial,
data=train_data)
summary(initial_model)
#Model with most significant variables from the initial model
model1<-glm(formula = train_data$Customer_Status ~ Checking.account.Status_A13 +
Checking.account.Status_A14 + Credit.history_A34 +
Purpose_A41 + Purpose_A42 + Purpose_A43 +
Savings.account.bonds_A62 + Savings.account.bonds_A65 +
Other.debtors...guarantors_A102 +
Other.installment.plans_A143 +
foreign.worker_A202 + `Duration in month` + `Credit amount` +
`Installment rate in % disposable income`,
family = binomial, data = train_data)
summary(model1)
test_new<-test_data[,c('Checking.account.Status_A13',
'Checking.account.Status_A14','Credit.history_A34',
'Purpose_A41','Purpose_A42','Purpose_A43',
'Savings.account.bonds_A62','Savings.account.bonds_A65',
'Other.debtors...guarantors_A102',
'Other.installment.plans_A143',
'foreign.worker_A202','Duration in month','Credit amount',
'Installment rate in % disposable income','Customer_Status')]
#Calculate the predicted probabilities for the test data using 0.5 as threshold
predicted<- predict(model1,test_new,type = "response" )
predicted_int<-as.integer(predicted>0.5)
tab<-table(predicted_int, test_new$Customer_Status)
con<-confusionMatrix(tab)
con
#Trying some more thresholds to see the accuracy
#Threshold 0.3
predicted_int1<-as.integer(predicted>0.3)
tab1<-table(predicted_int1, test_new$Customer_Status)
con1<-confusionMatrix(tab1)
con1
#Threshold 0.6
predicted_int2<-as.integer(predicted>0.2)
tab2<-table(predicted_int2, test_new$Customer_Status)
con2<-confusionMatrix(tab2)
con2
#Plotting ROC
roc_curve<-roc(test_new$Customer_Status,predicted_int)
plot(roc_curve)
roc_curve$auc
loss <- c()
for(i in 1:100)
{
y_hat_round <- as.integer(predicted > (i/100)) # calculate threshold predictions
tm <-as.matrix(table(y_hat_round,test_new$Customer_Status))
if(nrow(tm)>1) { c1 <- tm[2,1] } else { c1 <- 0 }
if(ncol(tm)>1) { c2 <- tm[1,2] } else { c2 <- 0 }
loss <- c(loss, c2*5 + c1)
}
plot(c(1:100)/100,loss,xlab = "Threshold",ylab = "Loss",main = "Loss vs Threshold")
which.min(loss)
loss
load_packages <- c("ggplot2","car","Hmisc","ROCR","caret","dummies","caTools",
"MASS", "gridExtra")
model_score_test <- prediction(test_new$predicted_probs,test_new$Customer_Status)
con2<-confusionMatrix(tab2,positive = '1')
con2
#Calculate the predicted probabilities for the test data using 0.5 as threshold
predicted<- predict(model1,test_new,type = "response" )
predicted_int<-as.integer(predicted>0.5)
tab<-table(predicted_int, test_new$Customer_Status)
con<-confusionMatrix(tab,positive = '1')
con
#Trying some more thresholds to see the accuracy
#Threshold 0.3
predicted_int1<-as.integer(predicted>0.3)
tab1<-table(predicted_int1, test_new$Customer_Status)
con1<-confusionMatrix(tab1,positive = '1')
con1
#Threshold 0.6
predicted_int2<-as.integer(predicted>0.2)
#Threshold 0.6
predicted_int6<-as.integer(predicted>0.6)
tab6<-table(predicted_int6, test_new$Customer_Status)
con6<-confusionMatrix(tab6,positive = '1')
con6
#Threshold 0.4
predicted_int4<-as.integer(predicted>0.4)
tab4<-table(predicted_int4, test_new$Customer_Status)
con4<-confusionMatrix(tab4,positive = '1')
con4
#Threshold 0.2
predicted_int2<-as.integer(predicted>0.2)
tab2<-table(predicted_int2, test_new$Customer_Status)
con2<-confusionMatrix(tab2,positive = '1')
con2
#Threshold 0.1
predicted_int1<-as.integer(predicted>0.1)
tab1<-table(predicted_int2, test_new$Customer_Status)
con1<-confusionMatrix(tab2,positive = '1')
con1
